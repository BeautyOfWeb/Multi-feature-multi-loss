{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "import functools\n",
    "import collections\n",
    "import sys\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sys.path.append('C:/Users/Tianle/Documents/cs231n/spring1617/my-scripts')\n",
    "from dl.utils.gen_conv_params import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process clinical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clinicalfiles = ['clinical/' + v for v in os.listdir('clinical') \n",
    "                 if not re.search('Dict|Fields|clinical|overlapping', v)]\n",
    "# read seven .csv files:\n",
    "clinicalfiles_acronym = ['train', 'sc1_val', 'sc1_train', 'sc2_val', 'sc2_train', \n",
    "                         'sc3_val', 'sc3_train']\n",
    "\n",
    "clinical_info = {}\n",
    "for i, file in enumerate(clinicalfiles):\n",
    "    clinical = []\n",
    "    with open(file) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            clinical.append(row)\n",
    "    # The first row is feature names\n",
    "    var_names = clinical[0]\n",
    "    # Map feature name to idx\n",
    "    var_names = {name: i for i, name in enumerate(var_names)}\n",
    "    del clinical[0]\n",
    "    clinical_info[clinicalfiles_acronym[i]] = (clinical, var_names)\n",
    "\n",
    "path = 'processed_data/'\n",
    "fileName = 'clinical_info.pkl'\n",
    "with open(path + fileName, 'wb') as f:\n",
    "    pickle.dump(clinical_info, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "clinical, var_names = clinical_info['train']\n",
    "\n",
    "# Patient ID are unique\n",
    "assert len([v[1] for v in clinical]) == len(set([v[1] for v in clinical]))\n",
    "\n",
    "# SamplId are unique if not 'NA'\n",
    "# This allows using (filename, sampleID) or just sampleID to find patientID\n",
    "for name in [v for v in var_names if re.search('SamplId', v)]:\n",
    "    sids = [v[var_names[name]] for v in clinical\n",
    "            if v[var_names[name]] != 'NA']\n",
    "    print(name, len(sids))\n",
    "    assert len(sids) == len(set(sids))\n",
    "\n",
    "# Find expression files in two folders: MA and RNA-seq\n",
    "expfiles = [(root, files) for root, subdir, files in os.walk('Expression Data/') if len(files) > 0]\n",
    "# Select files with entrezID\n",
    "expfilepaths = [[os.path.join(root, f) for f in files if re.search('entrezID', f)] \n",
    "                for root, files in expfiles]\n",
    "# Save filenames\n",
    "expfilenames = [[f for f in files if re.search('entrezID', f)] for root, files in expfiles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# do not use 'CENSORED' or 'D_PFS' <= 30 (might be error in the data)\n",
    "clinical = [v for v in clinical if v[var_names['HR_FLAG']] != 'CENSORED' \n",
    "       and float(v[var_names['D_PFS']]) > 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Overlapping entrezIds\n",
    "entrez_ids = []\n",
    "with open('clinical/overlappingEntrezIds.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        entrez_ids.append(row)\n",
    "\n",
    "entrez_ids = [v[0] for i, v in enumerate(entrez_ids) if i > 0]\n",
    "\n",
    "# Ensure entrez_ids is ordered\n",
    "idx_entrezIds = np.array(entrez_ids).argsort()\n",
    "entrez_ids = [entrez_ids[i] for i in idx_entrezIds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare RNA-seq gene expression data (only one file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp = []\n",
    "with open(expfilepaths[1][0]) as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for row in reader:\n",
    "        exp.append(row)\n",
    "\n",
    "sampleIds = [n for i, n in enumerate(exp[0]) if i > 0]\n",
    "sampleIds = {sid: i for i, sid in enumerate(sampleIds)}\n",
    "# (idx_clinical, idx_exp) map samples that have both clinical data and exp data \n",
    "idx_map = [(i, sampleIds[v[var_names['RNASeq_geneLevelExpFileSamplId']]]) \n",
    "           for i, v in enumerate(clinical) \n",
    "           if v[var_names['RNASeq_geneLevelExpFile']] in expfilenames[1] \n",
    "           and v[var_names['RNASeq_geneLevelExpFileSamplId']] in sampleIds]\n",
    "entrezIds = [v[0] for i, v in enumerate(exp) if i > 0]\n",
    "# sort entrezIds\n",
    "idx_entrezIds = np.array(entrezIds).argsort()\n",
    "entrezIds = [entrezIds[i] for i in idx_entrezIds]\n",
    "exp = [[float(e) if e != 'NA' else 0 for j, e in enumerate(v) if j > 0]\n",
    "       for i, v in enumerate(exp) if i > 0]\n",
    "exp = np.array(exp)\n",
    "exp = exp.T\n",
    "exp = exp[[idx_exp for idx_clinical, idx_exp in idx_map]]\n",
    "exp = exp[:, idx_entrezIds]\n",
    "assert set(entrez_ids) <= set(entrezIds)\n",
    "idx_entrezIds = [entrezIds.index(v) for v in entrez_ids]\n",
    "exp = exp[:, idx_entrezIds]\n",
    "exp_rnaseq = np.log2(exp + 1)\n",
    "\n",
    "clinical_rnaseq = [clinical[idx_clinical] for idx_clinical, idx_exp in idx_map]\n",
    "y_rnaseq = [v[var_names['HR_FLAG']] for v in clinical_rnaseq]\n",
    "\n",
    "path = 'processed_data/'\n",
    "fileName = 'rnaseq_features_unnormalized.pkl'\n",
    "with open(path + fileName, 'wb') as f:\n",
    "    pickle.dump({'exp': exp_rnaseq, 'y': y_rnaseq, 'entrezIds': entrez_ids, \n",
    "                 'clinical': clinical_rnaseq, 'var_names': var_names}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare microarray gene expression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "microarray = {}\n",
    "for i, expfile in enumerate(expfilepaths[0]):\n",
    "    exp = []\n",
    "    with open(expfile) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            exp.append(row)\n",
    "    # First row are sample ids, and first column is entrezIDs \n",
    "    sampleIds = [n for i, n in enumerate(exp[0]) if i > 0]\n",
    "    sampleIds = {sid: i for i, sid in enumerate(sampleIds)}\n",
    "    # (idx_clinical, idx_exp) map samples that have both clinical data and exp data \n",
    "    idx_map = [(i, sampleIds[v[var_names['MA_geneLevelExpFileSamplId']]]) \n",
    "               for i, v in enumerate(clinical) \n",
    "               if v[var_names['MA_geneLevelExpFile']] in expfilenames[0] \n",
    "               and v[var_names['MA_geneLevelExpFileSamplId']] in sampleIds]\n",
    "    entrezIds = [v[0] for i, v in enumerate(exp) if i > 0]\n",
    "    # sort entrezIds\n",
    "    idx_entrezIds = np.array(entrezIds).argsort()\n",
    "    entrezIds = [entrezIds[i] for i in idx_entrezIds]\n",
    "    # There are very few 'NA' values. Set them to 0\n",
    "    exp = [[float(e) if e != 'NA' else 0 for j, e in enumerate(v) if j > 0] \n",
    "           for i, v in enumerate(exp) if i > 0]\n",
    "    exp = np.array(exp)\n",
    "    exp = exp.T\n",
    "    exp = exp[[idx_exp for idx_clinical, idx_exp in idx_map]]\n",
    "    exp = exp[:, idx_entrezIds]\n",
    "    assert set(entrez_ids) <= set(entrezIds)\n",
    "    idx_entrezIds = [entrezIds.index(v) for v in entrez_ids]\n",
    "    exp = exp[:, idx_entrezIds]\n",
    "    print(expfile, len(sampleIds), exp.shape)\n",
    "    microarray[expfilenames[0][i]] = {'exp': exp, 'idx_clinical': [i for i, j in idx_map], \n",
    "                                      'entrezIds': entrez_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ma_exp = []\n",
    "idx_clinical = []\n",
    "for k, v in microarray.items():\n",
    "    ma_exp.append(v['exp'])\n",
    "    idx_clinical = idx_clinical + v['idx_clinical']\n",
    "\n",
    "exp_ma = np.concatenate(ma_exp, axis=0)\n",
    "\n",
    "clinical_ma = [clinical[i] for i in idx_clinical]\n",
    "\n",
    "y_ma = [v[var_names['HR_FLAG']] for v in clinical_ma]\n",
    "path = 'processed_data/'\n",
    "fileName = 'ma_features_unnormalized.pkl'\n",
    "with open(path + fileName, 'wb') as f:\n",
    "    pickle.dump({'exp': exp_ma, 'y': y_ma, 'entrezIds': entrez_ids, \n",
    "                 'clinical': clinical_ma, 'var_names': var_names}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess reactome pathway data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'F:/KnowledgeBases/processedData/'\n",
    "filename = path + 'ncbi2reactome.csv'\n",
    "gene_pathway = []\n",
    "with open(filename) as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    for v in reader:\n",
    "        gene_pathway.append(v)\n",
    "gene_to_pathway = collections.defaultdict(list)\n",
    "pathway_to_gene = collections.defaultdict(list)\n",
    "for entrezID, pathwayID in gene_pathway:\n",
    "    gene_to_pathway[pathwayID].append(entrezID)\n",
    "    pathway_to_gene[entrezID].append(pathwayID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gene_filter_cor_std(exp, clinical, entrezIds, filter_below=0.10, eps=1e-8):\n",
    "    assert isinstance(exp, np.ndarray)\n",
    "    # First filter out genes with std <= eps\n",
    "    std = np.std(exp, axis=0)\n",
    "    idx = np.where(std > eps)[0]\n",
    "    std = std[idx]\n",
    "    exp = exp[:, idx]\n",
    "    entrezIds = [e for i, e in enumerate(entrezIds) if i in idx]\n",
    "    y_tmp = np.array([[float(v[var_names['D_PFS']]), float(v[var_names['D_OS']]),\n",
    "                     float(v[var_names['D_OS_FLAG']]), float(v[var_names['D_PFS_FLAG']]),\n",
    "                     1 if v[var_names['HR_FLAG']] == 'TRUE' else 0] for v in clinical])\n",
    "    cor = np.corrcoef(np.concatenate([exp, y_tmp], axis=1), rowvar=False)\n",
    "    # corrcoef between y and entrezIds\n",
    "    cor = cor[:exp.shape[1], -5:]\n",
    "    # based on intuition\n",
    "    cor_std = np.mean(np.abs(cor) * std[:, None], axis=1)\n",
    "    # filter out entrezIds that have a small cor_std value\n",
    "    idx = np.where(cor_std - min(cor_std) > (max(cor_std) - min(cor_std)) * filter_below)[0]\n",
    "    exp = exp[:, idx]\n",
    "    entrezIds = [e for i, e in enumerate(entrezIds) if i in idx]\n",
    "    return exp, entrezIds\n",
    "\n",
    "_, genes1 = gene_filter_cor_std(exp_rnaseq, clinical_rnaseq, entrez_ids)\n",
    "_, genes2 = gene_filter_cor_std(exp_ma, clinical_ma, entrez_ids)\n",
    "\n",
    "genes = sorted(set(genes1).intersection(genes2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx_to_gene = {e: [i] for i, e in enumerate(genes)}\n",
    "res = reduce_projections([idx_to_gene, gene_to_pathway, pathway_to_gene, \n",
    "                         gene_to_pathway, pathway_to_gene, gene_to_pathway, \n",
    "                         pathway_to_gene, gene_to_pathway, pathway_to_gene])\n",
    "num_elements = [len(v) for v in res[0]]\n",
    "print('number of elements from the first layer to last layer:\\n{0}'\n",
    "      .format(num_elements))\n",
    "\n",
    "k = len(num_elements) - 2\n",
    "for i in range(len(num_elements) - 1, 3, -1):\n",
    "    if (num_elements[i], num_elements[i-1]) == (num_elements[i-2], num_elements[i-3]):\n",
    "        k = k - 1\n",
    "    else:\n",
    "        break\n",
    "if k < len(num_elements) - 2:\n",
    "    print('From {0}th layer, repeat'.format(k))\n",
    "    for i in range(k, len(num_elements)-2):\n",
    "        assert res[0][i] == res[0][i + 2]\n",
    "        assert res[1][i] == res[1][i + 2]\n",
    "    # k-1 and k+1 layers are almost the same\n",
    "    assert res[0][k-1].keys() == res[0][k+1].keys()\n",
    "    c = 0\n",
    "    for p, v in res[0][k-1].items():\n",
    "        v1 = set([res[1][k-1][e] for e in v])\n",
    "        v2 = set([res[1][k+1][e] for e in res[0][k+1][p]])\n",
    "        assert v1 <= v2\n",
    "        if v1 < v2:\n",
    "            c += 1\n",
    "    print('{0} genes/pathways connect to less pathways/genes in layer {1} (res[0][{1}])'\n",
    "          .format(c, k-1))\n",
    "else:\n",
    "    print('No repeat, check the input again!')\n",
    "\n",
    "idx = [entrez_ids.index(g) for g in res[1][1]]\n",
    "exp_ma = exp_ma[:, idx]\n",
    "exp_rnaseq = exp_rnaseq[:, idx]\n",
    "entrez_ids = res[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = 'processed_data/'\n",
    "filename = 'exp_features_unnormalized.pkl'\n",
    "with open(path+filename, 'wb') as f:\n",
    "    pickle.dump({'exp_ma': exp_ma, 'exp_rnaseq': exp_rnaseq, \n",
    "                 'clinical_ma': clinical_ma, 'clinical_rnaseq': clinical_rnaseq,\n",
    "                 'entrezIds': entrez_ids, 'var_names': var_names, 'res': res}, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
